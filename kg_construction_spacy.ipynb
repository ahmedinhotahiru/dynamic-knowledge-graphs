{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extract Text from the PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use the PyMuPDF library (fitz) to extract text from the PDF. This library is effective for handling structured text, such as reports and tables, commonly found in survey data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Function to extract text from each page in the PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "\n",
    "    print(\"\\nExtracting text from the file...\")\n",
    "\n",
    "    # Open the PDF file\n",
    "    document = fitz.open(file_path)\n",
    "    text_data = []\n",
    "\n",
    "    # Iterate through each page\n",
    "    for page_num in range(document.page_count):\n",
    "        page = document[page_num]\n",
    "        page_text = page.get_text()  # Extract text from page\n",
    "        text_data.append(page_text)\n",
    "\n",
    "    document.close()\n",
    "    print(\"\\nCompleted successfully!\")\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting text from the file...\n",
      "\n",
      "Completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Path to the PDF file\n",
    "# file_path = 'files/Final_SAS 2023_Annual Report.pdf'\n",
    "file_path = 'files/Agricult_data.pdf'\n",
    "pdf_text = extract_text_from_pdf(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_extracted_text(pdf_text):\n",
    "    print(\"\\nSample of first few pages of extracted text:\\n\")\n",
    "\n",
    "    # Check the first few pages to see the extracted text\n",
    "    for i, page in enumerate(pdf_text[:3]):\n",
    "        print(f\"--- Page {i+1} ---\")\n",
    "        print(page[:500])  # Print first 500 characters for preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of first few pages of extracted text:\n",
      "\n",
      "--- Page 1 ---\n",
      "[ \n",
      "    { \n",
      "    \"instruction\": \"Answer the following question\", \n",
      "    \"input\": \"What are some methods for improving soil fertility?\", \n",
      "    \"response\": \"Improving soil fertility can be achieved through various \n",
      "methods such as crop rotation, cover cropping, and adding organic matter \n",
      "like compost or manure. Additionally, using green manures, practicing \n",
      "conservation tillage, and applying appropriate fertilizers based on soil \n",
      "testing can help enhance soil fertility and promote healthier plant \n",
      "growt\n",
      "--- Page 2 ---\n",
      "or brush piles, and avoiding or minimizing pesticide use to protect \n",
      "pollinator populations. Creating diverse landscapes with a variety of \n",
      "flowering plants and maintaining habitat corridors can also support \n",
      "pollinator health and biodiversity on the farm.\" \n",
      "    }, \n",
      "    { \n",
      "    \"instruction\": \"Answer the following question\", \n",
      "    \"input\": \"What are some methods for improving soil health in organic \n",
      "farming?\", \n",
      "    \"response\": \"Improving soil health in organic farming involves \n",
      "practices such as c\n",
      "--- Page 3 ---\n",
      "areas to reduce water consumption by animals are also effective \n",
      "strategies for water conservation.\" \n",
      "    }, \n",
      "    { \n",
      "    \"instruction\": \"Answer the following question\", \n",
      "    \"input\": \"How can I minimize the environmental impact of pesticide \n",
      "use in agriculture?\", \n",
      "    \"response\": \"Minimizing the environmental impact of pesticide use in \n",
      "agriculture involves practices like using integrated pest management \n",
      "(IPM) strategies to reduce reliance on chemical pesticides. Implementing \n",
      "biological contro\n"
     ]
    }
   ],
   "source": [
    "display_extracted_text(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll implement the following preprocessing steps:\n",
    "\n",
    "- Remove Extra Spaces and Line Breaks: To make the text easier to work with.\n",
    "\n",
    "- Split Text into Sentences: This will help with processing the text sentence by sentence during entity extraction.\n",
    "\n",
    "- Normalize Case and Remove Unwanted Characters: For consistent analysis, we’ll standardize the case and remove characters like page numbers, special symbols, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ahmed Issah\n",
      "[nltk_data]     Tahiru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# download nltk toketizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Ahmed Issah\n",
      "[nltk_data]     Tahiru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess_text(text_data):\n",
    "    \n",
    "    print(\"\\nPreprocessing extracted text...\")\n",
    "\n",
    "    processed_text = []\n",
    "\n",
    "    for page_text in text_data:\n",
    "        # Remove any extraneous whitespace and newlines\n",
    "        page_text = page_text.replace('\\n', ' ').strip()\n",
    "\n",
    "        # Remove unwanted characters like page numbers or table of contents markers\n",
    "        page_text = re.sub(r'\\bPage\\s\\d+\\b', '', page_text)\n",
    "        page_text = re.sub(r'[^a-zA-Z0-9\\s.,]', '', page_text)\n",
    "\n",
    "        # Convert text to lowercase\n",
    "        page_text = page_text.lower()\n",
    "\n",
    "        # Tokenize text into sentences\n",
    "        sentences = sent_tokenize(page_text)\n",
    "\n",
    "        # Store cleaned sentences\n",
    "        processed_text.extend(sentences)\n",
    "\n",
    "    print(\"\\nCompleted successfully!\")\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing extracted text...\n",
      "\n",
      "Completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the extracted text\n",
    "cleaned_text = preprocess_text(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display preprocessed text\n",
    "def display_preprocessed_text(cleaned_text):\n",
    "\n",
    "    print(\"\\nSample of first few cleaned sentences:\\n\")\n",
    "\n",
    "    # Display the first few cleaned sentences\n",
    "    for i, sentence in enumerate(cleaned_text[:20]):\n",
    "        print(f\"Sentence {i+1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of first few cleaned sentences:\n",
      "\n",
      "Sentence 1:             instruction answer the following question,      input what are some methods for improving soil fertility,      response improving soil fertility can be achieved through various  methods such as crop rotation, cover cropping, and adding organic matter  like compost or manure.\n",
      "Sentence 2: additionally, using green manures, practicing  conservation tillage, and applying appropriate fertilizers based on soil  testing can help enhance soil fertility and promote healthier plant  growth.\n",
      "Sentence 3: ,            instruction answer the following question,      input how can i prevent erosion on my farmland,      response preventing erosion on farmland involves implementing  conservation practices like contour plowing, terracing, and planting  windbreaks or cover crops.\n",
      "Sentence 4: maintaining vegetation along waterways,  installing silt fences, and using erosion control blankets can also help  minimize soil erosion and protect the integrity of farmland.\n",
      "Sentence 5: ,            instruction answer the following question,      input what are some sustainable pest management techniques for  crops,      response implementing sustainable pest management techniques for  crops includes practices like integrated pest management ipm, where  biological controls, cultural practices, and chemical controls are used  in combination to minimize pest damage while reducing reliance on  synthetic pesticides.\n",
      "Sentence 6: crop rotation, using resistant crop varieties, and  promoting natural predators of pests are also effective strategies for  sustainable pest management.\n",
      "Sentence 7: ,            instruction answer the following question,      input how can i improve water efficiency in agriculture,      response improving water efficiency in agriculture can be  achieved through practices like drip irrigation, which delivers water  directly to the roots of plants, minimizing evaporation and runoff.\n",
      "Sentence 8: implementing watersaving technologies such as soil moisture sensors,  adopting conservation tillage methods, and utilizing rainwater harvesting  systems can also help optimize water use in agriculture.\n",
      "Sentence 9: ,            instruction answer the following question,      input what are some strategies for mitigating climate change  impacts on agriculture,      response mitigating climate change impacts on agriculture  involves implementing practices like agroforestry, which combines trees  and crops to sequester carbon dioxide and improve soil health.\n",
      "Sentence 10: additionally, adopting droughtresistant crop varieties, practicing crop  diversification, and implementing soil conservation measures can help  agriculture become more resilient to the effects of climate change.\n",
      "Sentence 11: ,            instruction answer the following question,      input how can i enhance pollinator habitat on my farm,      response enhancing pollinator habitat on a farm can be done by  planting native flowering plants, providing nesting sites like bee hotels\n",
      "Sentence 12: or brush piles, and avoiding or minimizing pesticide use to protect  pollinator populations.\n",
      "Sentence 13: creating diverse landscapes with a variety of  flowering plants and maintaining habitat corridors can also support  pollinator health and biodiversity on the farm.\n",
      "Sentence 14: ,            instruction answer the following question,      input what are some methods for improving soil health in organic  farming,      response improving soil health in organic farming involves  practices such as crop rotation, adding organic amendments like compost  or green manures, and minimizing soil disturbance through notill or  reduced tillage methods.\n",
      "Sentence 15: utilizing cover crops, practicing agroecology  principles, and fostering soil microbial activity through diverse crop  rotations can also enhance soil health in organic farming systems.\n",
      "Sentence 16: ,            instruction answer the following question,      input how can i manage nutrient runoff from my agricultural  operations,      response managing nutrient runoff from agricultural operations  requires implementing practices such as planting buffer strips along  waterways, constructing vegetated swales or bioretention ponds, and  utilizing precision nutrient application techniques to minimize excess  fertilizer application.\n",
      "Sentence 17: implementing conservation practices like  conservation tillage and cover cropping can also help reduce nutrient  runoff and protect water quality.\n",
      "Sentence 18: ,            instruction answer the following question,      input what are some ways to increase biodiversity on a farm,      response increasing biodiversity on a farm can be achieved  through practices like establishing wildlife habitats such as hedgerows,  ponds, or wildflower meadows, and creating diverse crop rotations with  multiple species.\n",
      "Sentence 19: implementing agroecological principles, avoiding  monoculture farming, and providing habitat for beneficial insects and  wildlife can help promote biodiversity and ecosystem resilience on the  farm.\n",
      "Sentence 20: ,            instruction answer the following question,      input how can i manage soil salinity in my agricultural fields,      response managing soil salinity in agricultural fields involves  practices such as improving drainage through tile drainage or subsoil  drainage systems, leaching excess salts with irrigation water, and  incorporating gypsum or organic matter to help flocculate soil particles  and reduce salinity.\n"
     ]
    }
   ],
   "source": [
    "# display preprocessed text\n",
    "display_preprocessed_text(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Entity Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use spaCy, an NLP library that provides pre-trained models for named entity recognition (NER), part-of-speech tagging, and other text processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Install spaCy and Download Language Model\n",
    "If not already installed, we’ll install spaCy and download the en_core_web_sm model, which is spaCy's small English language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install spacy\n",
    "# %python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Extracting Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy's pre-trained English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract entities from the text\n",
    "def extract_entities(text_data):\n",
    "    \n",
    "    print(\"\\nExtracting entitites...\")\n",
    "\n",
    "    # entities = []\n",
    "    unique_entities = set()\n",
    "\n",
    "    for sentence in text_data:\n",
    "\n",
    "        # Process each sentence using spaCy's NLP pipeline\n",
    "        doc = nlp(sentence)\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            # Append each recognized entity and its label\n",
    "            # entities.append((ent.text, ent.label_))\n",
    "            \n",
    "            # Add each recognized entity and its label as a tuple\n",
    "            unique_entities.add((ent.text, ent.label_))\n",
    "\n",
    "    print(\"\\nCompleted successfully!\")\n",
    "    \n",
    "\n",
    "    return list(unique_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting entitites...\n",
      "\n",
      "Completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# apply entity extraction on the cleaned text\n",
    "extracted_entities = extract_entities(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display a sample of extracted entities\n",
    "def display_extracted_entities(extracted_entities):\n",
    "\n",
    "    print(\"\\nSample of extracted entities:\\n\")\n",
    "\n",
    "    for i, entity in enumerate(extracted_entities[:20]):\n",
    "        print(f\"Entity {i+1}: Text: '{entity[0]}', Label: {entity[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of extracted entities:\n",
      "\n",
      "Entity 1: Text: 'nu2019okukyusakyusa', Label: PRODUCT\n",
      "Entity 2: Text: 'okulongoosa ettaka', Label: PERSON\n",
      "Entity 3: Text: 'ennungi eyamba', Label: PERSON\n",
      "Entity 4: Text: 'ngu2019ebibya', Label: GPE\n",
      "Entity 5: Text: 'kwagala bika', Label: ORG\n",
      "Entity 6: Text: 'byu2019ebimera.nnensonga', Label: GPE\n",
      "Entity 7: Text: 'mu mutendera', Label: PERSON\n",
      "Entity 8: Text: 'ekituufu.nkikulu', Label: PRODUCT\n",
      "Entity 9: Text: 'okusaawa omuddo buli', Label: PERSON\n",
      "Entity 10: Text: '2177      ', Label: TIME\n",
      "Entity 11: Text: 'obugumu  obwu2019obutonde eri ebiwuka', Label: PERSON\n",
      "Entity 12: Text: 'okutangira ebiwuka  okuyingira', Label: PERSON\n",
      "Entity 13: Text: 'about half', Label: CARDINAL\n",
      "Entity 14: Text: 'kola amangu', Label: PERSON\n",
      "Entity 15: Text: 'below 18 degrees', Label: QUANTITY\n",
      "Entity 16: Text: 'night', Label: TIME\n",
      "Entity 17: Text: 'ebiwuka ebiyitibwa bean beetles', Label: ORG\n",
      "Entity 18: Text: 'kisigala oba ne kyeyongera', Label: PERSON\n",
      "Entity 19: Text: 'naddala eri abalimi', Label: PERSON\n",
      "Entity 20: Text: 'nayitrojeni mu ttaka  nu2019okugattako', Label: PERSON\n"
     ]
    }
   ],
   "source": [
    "# Display a sample of extracted entities\n",
    "display_extracted_entities(extracted_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2861"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity Types to Note for Agricultural Data\n",
    "- ORG: Organizations or institutions (e.g., \"National Institute of Statistics of Rwanda\").\n",
    "- DATE: Dates, which may relate to crop seasons.\n",
    "- GPE/LOC: Geopolitical entities or locations relevant to land use or agricultural regions.\n",
    "- CARDINAL/QUANTITY: Quantities often related to measurements or crop statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Relationship Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll analyze the extracted sentences to identify relationships between entities. For instance, relationships like \"maize grows in\" a specific season or \"fertilizer applied to\" certain crops can provide valuable insights for building a structured knowledge graph.\n",
    "\n",
    "We’ll use dependency parsing, which identifies syntactic relationships between words in a sentence. spaCy’s dependency parser will help us capture these relationships, focusing on:\n",
    "\n",
    "- Subject-Verb-Object (SVO) triples: Common in sentences that describe actions, like \"farmers use fertilizers.\"\n",
    "- Prepositional Phrases: Often contain location or temporal data, like \"in season A.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract relationships from sentences\n",
    "\n",
    "def extract_relationships(text_data):\n",
    "\n",
    "    print(\"\\nExtracting relationships...\")\n",
    "\n",
    "\n",
    "    # container to store extracted relationships\n",
    "    relationships = set()\n",
    "    # relationships = []\n",
    "\n",
    "\n",
    "\n",
    "    # Loop through each sentence in the text to extract relationships \n",
    "    for sentence in text_data:\n",
    "        doc = nlp(sentence)\n",
    "\n",
    "        # Define placeholders for entities and relationships\n",
    "        subject = None\n",
    "        predicate = None\n",
    "        obj = None\n",
    "\n",
    "        # Dependency parsing to identify SVO structure\n",
    "        for token in doc:\n",
    "\n",
    "            # Find the subject (usually a noun or a compound noun)\n",
    "            if \"subj\" in token.dep_:\n",
    "                subject = token.text\n",
    "\n",
    "            # Find the object (usually a noun or a compound noun)\n",
    "            elif \"obj\" in token.dep_:\n",
    "                obj = token.text\n",
    "\n",
    "            # Find the main verb (predicate of the sentence)\n",
    "            elif token.pos_ == \"VERB\":\n",
    "                # Use lemma for consistent verbs (e.g., 'use' vs 'used')\n",
    "                predicate = token.lemma_\n",
    "\n",
    "        # If SVO structure is found, store the relationship\n",
    "        if subject and predicate and obj:\n",
    "            relationships.add((subject, predicate, obj))\n",
    "            # relationships.append((subject, predicate, obj))\n",
    "\n",
    "    print(\"\\nCompleted successfully!\")\n",
    "\n",
    "    return list(relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting relationships...\n",
      "\n",
      "Completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Apply relationship extraction on cleaned text\n",
    "extracted_relationships = extract_relationships(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display a sample of extracted relationships\n",
    "def display_extracted_relationships(extracted_relationships):\n",
    "    \n",
    "    print(\"\\nSample of extracted relationships:\\n\")\n",
    "\n",
    "    for i, relationship in enumerate(extracted_relationships[:20]):\n",
    "        print(f\"Relationship {i+1}: Subject: '{relationship[0]}', Predicate: '{relationship[1]}', Object: '{relationship[2]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of extracted relationships:\n",
      "\n",
      "Relationship 1: Subject: 'implementing', Predicate: 'mitigate', Object: 'issues'\n",
      "Relationship 2: Subject: 'okuteeka', Predicate: 'ebanga', Object: 'question'\n",
      "Relationship 3: Subject: 'cassava', Predicate: 'yield', Object: 'wetlands'\n",
      "Relationship 4: Subject: 'implementing', Predicate: 'promote', Object: 'growth'\n",
      "Relationship 5: Subject: 'waliwo', Predicate: 'pulogulaamu', Object: 'enteekateeka'\n",
      "Relationship 6: Subject: 'activities', Predicate: 'do', Object: 'termides'\n",
      "Relationship 7: Subject: 'suppliers', Predicate: 'visit', Object: 'area'\n",
      "Relationship 8: Subject: 'kind', Predicate: 'use', Object: 'moisture'\n",
      "Relationship 9: Subject: 'termites', Predicate: 'answer', Object: 'question'\n",
      "Relationship 10: Subject: 'implementing', Predicate: 'improve', Object: 'agriculture'\n",
      "Relationship 11: Subject: 'organisms', Predicate: 'improve', Object: 'structure'\n",
      "Relationship 12: Subject: 'overapplication', Predicate: 'lead', Object: 'imbalances'\n",
      "Relationship 13: Subject: 'which', Predicate: 'provide', Object: 'fungi'\n",
      "Relationship 14: Subject: 'utilizing', Predicate: 'improve', Object: 'orchards'\n",
      "Relationship 15: Subject: 'soil', Predicate: 'support', Object: 'germination'\n",
      "Relationship 16: Subject: 'bulungi', Predicate: 'agu2019okunywa', Object: 'lupapula'\n",
      "Relationship 17: Subject: 'akuwa', Predicate: 'eat', Object: 'yu2019ekitundu'\n",
      "Relationship 18: Subject: 'seeds', Predicate: 'space', Object: 'rows'\n",
      "Relationship 19: Subject: 'electricity', Predicate: 'input', Object: 'question'\n",
      "Relationship 20: Subject: 'plants', Predicate: 'promote', Object: 'growth'\n"
     ]
    }
   ],
   "source": [
    "# display a sample of extracted relationships\n",
    "display_extracted_relationships(extracted_relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2261"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Building the DKG with NetworkX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use the extracted entities and relationships to create a structured knowledge graph that models the agricultural information.\n",
    "\n",
    "To build the knowledge graph, we’ll use the NetworkX library in Python. This will allow us to represent entities as nodes and relationships as edges, creating a graph that can be easily updated and queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize an empty directed graph\n",
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the knowledge graph from entities and relationships\n",
    "def build_knowledge_graph_networkx(entities, relationships):\n",
    "\n",
    "    print(\"\\nBuilding knowledge Graph...\")\n",
    "\n",
    "    # Add entities as nodes\n",
    "    for entity, entity_type in entities:\n",
    "        if not G.has_node(entity): # Check if the node already exists\n",
    "            G.add_node(entity, label=entity_type)\n",
    "\n",
    "    # Add relationships as edges\n",
    "    for subject, predicate, obj in relationships:\n",
    "        if not G.has_edge(subject, obj):  # Check if the edge already exists between these 2 entities\n",
    "            G.add_edge(subject, obj, label=predicate)\n",
    "\n",
    "    print(\"\\nKnowledge Graph built successfully!\")\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building knowledge Graph...\n",
      "\n",
      "Knowledge Graph built successfully!\n"
     ]
    }
   ],
   "source": [
    "# Build the graph using extracted entities and relationships\n",
    "knowledge_graph = build_knowledge_graph_networkx(extracted_entities, extracted_relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install spicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Draw the graph\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# pos = nx.spring_layout(knowledge_graph, seed=42)  # Layout for visualization\n",
    "# nx.draw(knowledge_graph, pos, with_labels=True, node_size=3000, node_color=\"skyblue\", font_size=10, font_weight=\"bold\", edge_color=\"gray\")\n",
    "# edge_labels = nx.get_edge_attributes(knowledge_graph, \"label\")\n",
    "# nx.draw_networkx_edge_labels(knowledge_graph, pos, edge_labels=edge_labels, font_color=\"red\")\n",
    "# plt.title(\"Agricultural Knowledge Graph\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Graph with Pyvis and Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "def visualize_knowledge_graph_pyvis(G, output_path=\"knowledge_graph.html\"):\n",
    "    \"\"\"Visualize and save the graph using PyVis.\"\"\"\n",
    "    # Initialize PyVis network\n",
    "    net = Network(notebook=True, height=\"750px\", width=\"100%\",\n",
    "                  bgcolor=\"#ffffff\", font_color=\"black\", cdn_resources='remote')\n",
    "\n",
    "    # Customize the PyVis physics settings for better layout\n",
    "    net.set_options(\"\"\"\n",
    "    var options = {\n",
    "        \"nodes\": {\n",
    "            \"font\": {\"size\": 12},\n",
    "            \"size\": 20\n",
    "        },\n",
    "        \"edges\": {\n",
    "            \"color\": {\"color\": \"#000000\", \"opacity\": 0.5},\n",
    "            \"font\": {\"size\": 10},\n",
    "            \"smooth\": false\n",
    "        },\n",
    "        \"physics\": {\n",
    "            \"barnesHut\": {\n",
    "                \"gravitationalConstant\": -2000,\n",
    "                \"centralGravity\": 0.3,\n",
    "                \"springLength\": 200\n",
    "            },\n",
    "            \"minVelocity\": 0.75\n",
    "        }\n",
    "    }\n",
    "    \"\"\")\n",
    "\n",
    "    # Add nodes to the PyVis network\n",
    "    for node, attr in G.nodes(data=True):\n",
    "        net.add_node(node, label=node, color=attr.get(\"color\", \"skyblue\"))\n",
    "\n",
    "    # Add edges to the PyVis network with labels\n",
    "    for source, target, attr in G.edges(data=True):\n",
    "        net.add_edge(source, target, label=attr.get(\"label\", \"\"), arrows=\"to\")\n",
    "\n",
    "    # Save the graph as an HTML file\n",
    "    net.save_graph(output_path)\n",
    "    print(f\"Graph saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved to new_agricultural_knowledge_graph.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "visualize_knowledge_graph_pyvis(knowledge_graph, output_path=\"new_agricultural_knowledge_graph.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1: Extract Schema from Current Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Function to generate schema from entities and relationships\n",
    "def generate_schema(entities, relationships):\n",
    "\n",
    "    # Collect unique entity types\n",
    "    entity_types = set(entity_type for _, entity_type in entities)\n",
    "    \n",
    "    # Initialize dictionary to store relationship types\n",
    "    relationship_types = defaultdict(set)\n",
    "\n",
    "    # Populate relationship types based on current relationships\n",
    "    for subject, predicate, obj in relationships:\n",
    "\n",
    "        # Check if the subject and object have associated types\n",
    "        subject_type = next((etype for ename, etype in entities if ename == subject), None)\n",
    "        obj_type = next((etype for ename, etype in entities if ename == obj), None)\n",
    "\n",
    "        # Only add if both subject_type and obj_type exist\n",
    "        if subject_type and obj_type:\n",
    "            relationship_types[(subject_type, obj_type)].add(predicate)\n",
    "\n",
    "    # Convert relationship_types to a more readable format\n",
    "    relationship_schema = {k: list(v) for k, v in relationship_types.items()}\n",
    "\n",
    "    # Construct schema\n",
    "    schema = {\n",
    "        \"entities\": list(entity_types),\n",
    "        \"relationships\": relationship_schema\n",
    "    }\n",
    "    return schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Generated Schema:\n",
      "{'entities': ['FAC', 'PERSON', 'TIME', 'WORK_OF_ART', 'GPE', 'MONEY', 'CARDINAL', 'NORP', 'PRODUCT', 'QUANTITY', 'PERCENT', 'ORDINAL', 'DATE', 'LOC', 'ORG'], 'relationships': {('PERSON', 'GPE'): ['bivudde', 'sensa'], ('PERSON', 'CARDINAL'): ['kikulu'], ('PERSON', 'ORG'): ['waggulu'], ('GPE', 'ORG'): ['okufuuka', 'eritta'], ('DATE', 'GPE'): ['introduce'], ('LOC', 'NORP'): ['input'], ('CARDINAL', 'NORP'): ['nase'], ('NORP', 'ORG'): ['okwetooloola'], ('NORP', 'GPE'): ['gayitiridde'], ('ORG', 'PERSON'): ['omuli', 'focus'], ('GPE', 'NORP'): ['ebiramu'], ('PERSON', 'NORP'): ['bukulu'], ('PERSON', 'PERSON'): ['kimenyawo'], ('NORP', 'PERSON'): ['kiyamba']}}\n"
     ]
    }
   ],
   "source": [
    "# Generate schema based on extracted entities and relationships\n",
    "schema = generate_schema(extracted_entities, extracted_relationships)\n",
    "\n",
    "# Display the generated schema\n",
    "print(\"Auto-Generated Schema:\")\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': ['FAC',\n",
       "  'PERSON',\n",
       "  'TIME',\n",
       "  'WORK_OF_ART',\n",
       "  'GPE',\n",
       "  'MONEY',\n",
       "  'CARDINAL',\n",
       "  'NORP',\n",
       "  'PRODUCT',\n",
       "  'QUANTITY',\n",
       "  'PERCENT',\n",
       "  'ORDINAL',\n",
       "  'DATE',\n",
       "  'LOC',\n",
       "  'ORG'],\n",
       " 'relationships': {('PERSON', 'GPE'): ['bivudde', 'sensa'],\n",
       "  ('PERSON', 'CARDINAL'): ['kikulu'],\n",
       "  ('PERSON', 'ORG'): ['waggulu'],\n",
       "  ('GPE', 'ORG'): ['okufuuka', 'eritta'],\n",
       "  ('DATE', 'GPE'): ['introduce'],\n",
       "  ('LOC', 'NORP'): ['input'],\n",
       "  ('CARDINAL', 'NORP'): ['nase'],\n",
       "  ('NORP', 'ORG'): ['okwetooloola'],\n",
       "  ('NORP', 'GPE'): ['gayitiridde'],\n",
       "  ('ORG', 'PERSON'): ['omuli', 'focus'],\n",
       "  ('GPE', 'NORP'): ['ebiramu'],\n",
       "  ('PERSON', 'NORP'): ['bukulu'],\n",
       "  ('PERSON', 'PERSON'): ['kimenyawo'],\n",
       "  ('NORP', 'PERSON'): ['kiyamba']}}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: Real-Time KG Updates with Schema Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll implement a way to update the Dynamic Knowledge Graph (DKG) using the auto-generated schema. This will ensure new data is validated against the existing structure, keeping the graph consistent and accurate.\n",
    "\n",
    "In this step, we’ll:\n",
    "\n",
    "1. Validate New Data: Check that new entities and relationships align with the schema.\n",
    "2. Add Validated Data to the DKG: Update the graph with new data, preserving structure and relationships.\n",
    "3. Flag Inconsistent Data: If data doesn’t match the schema, it will be flagged for manual review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to do Real-Time Updates of the KG while storing Flagged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Containers to hold flagged entities and relationships\n",
    "flagged_entities, flagged_relationships = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_knowledge_graph_with_flagging(new_entities, new_relationships, graph, schema):\n",
    "    global flagged_entities, flagged_relationships\n",
    "\n",
    "    # Add entities with validation and ensure all nodes have a \"label\" attribute\n",
    "    for entity, entity_type in new_entities:\n",
    "        if entity_type in schema[\"entities\"]:\n",
    "            if not graph.has_node(entity):  # Avoid duplicate nodes\n",
    "                graph.add_node(entity, label=entity_type)\n",
    "        else:\n",
    "            flagged_entities.append((entity, entity_type))\n",
    "\n",
    "    # Add relationships with validation and handle missing labels\n",
    "    for subject, predicate, obj in new_relationships:\n",
    "        if graph.has_node(subject) and graph.has_node(obj):\n",
    "            \n",
    "            # Use get() with default label if missing\n",
    "            subject_type = graph.nodes[subject].get(\"label\", \"Unknown\")\n",
    "            obj_type = graph.nodes[obj].get(\"label\", \"Unknown\")\n",
    "            \n",
    "            valid_predicates = schema[\"relationships\"].get((subject_type, obj_type), [])\n",
    "            if predicate in valid_predicates:\n",
    "                if not graph.has_edge(subject, obj):  # Avoid duplicate edges\n",
    "                    graph.add_edge(subject, obj, label=predicate)\n",
    "            else:\n",
    "                flagged_relationships.append((subject, predicate, obj))\n",
    "        else:\n",
    "            flagged_relationships.append((subject, predicate, obj))\n",
    "\n",
    "    print(f\"Flagged Entities: {flagged_entities}\")\n",
    "    print(f\"Flagged Relationships: {flagged_relationships}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for New Data Extraction from PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll create a pipeline function to process a PDF file, extract new entities and relationships, and pass them to update_knowledge_graph_with_flagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_pdf(file_path):\n",
    "    global knowledge_graph, schema\n",
    "    \n",
    "    # Extract text from PDF\n",
    "    pdf_text = extract_text_from_pdf(file_path)\n",
    "    \n",
    "    # Preprocess extracted text\n",
    "    cleaned_text = preprocess_text(pdf_text)\n",
    "    \n",
    "    # Extract entities and relationships\n",
    "    new_entities = extract_entities(cleaned_text)\n",
    "    new_relationships = extract_relationships(cleaned_text)\n",
    "    \n",
    "    # Update knowledge graph with validation and flagging\n",
    "    update_knowledge_graph_with_flagging(new_entities, new_relationships, knowledge_graph, schema)\n",
    "    \n",
    "    # Return flagged items for review\n",
    "    return flagged_entities, flagged_relationships\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flagged_data(flagged_entities, flagged_relationships, entities_file=\"flagged_entities.json\", relationships_file=\"flagged_relationships.json\"):\n",
    "    # Save flagged entities to a file\n",
    "    with open(entities_file, \"w\") as ef:\n",
    "        json.dump(flagged_entities, ef, indent=4)\n",
    "    print(f\"\\nFlagged entities saved to {entities_file}\")\n",
    "\n",
    "    # Save flagged relationships to a file\n",
    "    with open(relationships_file, \"w\") as rf:\n",
    "        json.dump(flagged_relationships, rf, indent=4)\n",
    "    print(f\"\\nFlagged relationships saved to {relationships_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting text from the file...\n",
      "\n",
      "Completed successfully!\n",
      "\n",
      "Preprocessing extracted text...\n",
      "\n",
      "Completed successfully!\n",
      "\n",
      "Extracting entitites...\n",
      "\n",
      "Completed successfully!\n",
      "\n",
      "Extracting relationships...\n",
      "\n",
      "Completed successfully!\n",
      "Flagged Entities: []\n",
      "Flagged Relationships: [('category', 'grow', 'wood'), ('crop', 'cover', 'plot'), ('staff', 'maintain', 'quality'), ('survey', 'sample', 'sas'), ('denominator', 'equal', 'weights'), ('nyabihu', 'sas', 'nisr'), ('that', 'select', 'sample'), ('channels', 'sas', 'nisr'), ('which', 'measure', 'estimate'), ('area', 'pasture', 'season'), ('probability', 'follow', 'selection'), ('area', 'cultivate', 'maize'), ('collection', 'harvest', 'seasons'), ('survey', 'nyamasheke', 'rulindo'), ('proportion', 'harvest', 'area'), ('clustering', 'increase', 'segments'), ('kamonyi', 'sas', 'ssf'), ('dealers', 'sas', 'beer'), ('indicators', 'maize', 'beer'), ('karongi', 'sas', 'nisr'), ('karongi', 'sas', '74.7'), ('sample', 'draw', 'it'), ('which', 'express', 'area'), ('trade', 'sas', 'losses'), ('who', 'grow', 'season'), ('huye', 'sas', '51.84'), ('percentage', 'practice', '1,067.2'), ('area', 'exclude', 'crops1'), ('who', 'apply', 'year'), ('who', 'sas', 'nisr'), ('phase', 'cultivate', 'plots'), ('that', 'indicate', 'land'), ('survey', 'relate', 'statistics'), ('huye', 'sas', 'm.d'), ('that', 'bring', 'land'), ('that', 'have', 'crop'), ('crops', 'sas', 'beer'), ('barter', 'sas', 'crops'), ('share', 'plant', 'plot'), ('report', 'relate', 'year'), ('area', 'equal', 'area'), ('it', 'screen', 'phases'), ('farmer', 'harvest', 'trees'), ('area', 'compare', '2022'), ('land', 'indicate', 'agriculture'), ('data', 'table', 'annexes'), ('summary', 'kgha', 'fruits'), ('survey', 'sqm', 'statistics'), ('musanze', 'sas', 'nisr'), ('di', 'sas', 'nisr'), ('land', 'graze', 'land'), ('c', 'use', 'seeds'), ('area', 'consider', 'density'), ('rwamagana', 'sas', 'nisr'), ('this', 'protect', 'erosion'), ('it', 'prove', 'sample'), ('gasabo', 'nyamasheke', '47.0'), ('varieties', 'grow', 'others'), ('some', 'relate', 'activities'), ('enumerators', 'connect', 'tablet'), ('which', 'take', 'frame'), ('land', 'include', 'category'), ('concepts', 'exclude', 'bodies'), ('points', 'relate', 'use'), ('which', 'use', 'worldview'), ('dealers', 'nyamasheke', '100.00'), ('crops', 'replant', 'cocoa'), ('percentage', 'sas', 'nisr'), ('57.5', 'use', 'agriculture'), ('di', 'sas', 'gro'), ('hectares', 'use', 'pasture'), ('phase', 'engage', 'lsf'), ('which', 'replant', 'harvest'), ('it', 'target', 'seasons'), ('percent', 'apply', 'pesticides'), ('five', 'consider', 'frame'), ('it', 'cover', 'segments'), ('quantity', 'quantify', 'kilograms'), ('between16', 'sas', 'crops'), ('farmer', 'cultivate', 'area'), ('total', 'constitute', 'sample'), ('ruhango', 'sas', 'gakenke'), ('section', 'harvest', 'use'), ('it', 'include', 'inputs'), ('segments', 'distribute', 'criterion'), ('share', 'apply', 'area'), ('production', '2023cultivate', 'type'), ('seeds', 'use', 'which'), ('estimate', 'consider', '20'), ('land', 'fallow', 'years'), ('value', 'show', 'prices'), ('area', 'include', 'crops'), ('huye', 'sas', 'nisr'), ('crop', 'occupy', 'area'), ('classes', 'exclude', 'agriculture'), ('which', 'divide', 'estimate'), ('inputs', 'include', 'seeds'), ('karongi', 'sas', '17.49'), ('karongi', 'sas', 'kayonza'), ('y', 'h', '2'), ('which', 'relate', 'interval'), ('musanze', 'sas', '14,637'), ('area', 'occupy', 'crops'), ('error', 'measure', 'variance'), ('potato', 'grow', 'zone'), ('pesticides', 'use', 'which'), ('it', 'estimate', 'cultivation'), ('barter', 'sas', 'beer'), ('karongi', 'sas', 'gicumbi'), ('segment', 'select', 'which'), ('data', 'holding', 'country'), ('area', 'cultivate', 'area'), ('yield', 'harvest', 'crop'), ('example', 'calculate', 'crop'), ('variable', 'refer', 'plots'), ('cv', 'indicate', '15'), ('dealers', 'kayonza', 'nyagatare'), ('enumerators', 'sample', 'segment'), ('nyabihu', 'sas', 'farmers'), ('karongi', 'nyamasheke', '18.85'), ('production', 'compare', '2022'), ('area', 'cover', 'crops'), ('government', 'invest', 'addition'), ('i', 'accord', 'total'), ('ruhango', 'nyamasheke', 'musanze'), ('demand', 'increase', 'data'), ('sum', 'exceed', 'percent'), ('estimates', 'give', 'district'), ('which', 'cover', 'frame'), ('percent', 'compare', 'c.'), ('inputs', 'highlight', 'inputs'), ('results', 'evidencebase', 'sector'), ('value', 'be', 'range'), ('crops', 'sas', 'gicumbi'), ('stratum', 'consider', 'agriculture'), ('points', 'follow', 'points'), ('team', 'ensure', 'hectares'), ('karongi', 'sas', '100'), ('software', 'sample', 'data'), ('gasabo', 'sas', 'nisr'), ('di', 'sas', 'npk'), ('who', 'write', 'alexis'), ('level', 'provide', 'information'), ('farmer', 'harvest', 'purposes'), ('yield', 'estimate', 'hectare'), ('kicukiro', 'sas', '6,277'), ('musanze', 'sas', 'ngoma'), ('each', 'cover', 'country'), ('4', 'sample', 'figures'), ('plots', 'use', 'size'), ('yield', 'compare', 'farmers'), ('use', 'sas', 'nisr'), ('step', 'consider', 'frame'), ('sas', 'combine', 'frame'), ('percent', 'apply', 'farmers'), ('rusizi', 'sas', '1,411'), ('clusters', 'state', 'reasons'), ('combination', 'relate', 'statistics'), ('huye', 'sas', '1,411'), ('karongi', 'sas', '0.7'), ('collection', 'grow', 'segments'), ('percent', 'see', 'tables'), ('that', 'describe', 'use'), ('that', 'cluster', 'design'), ('errors', 'sample', 'samples'), ('karongi', 'gakenke', 'kayonza'), ('statistics', 'evidencebase', 'making'), ('it', 'determine', 'period'), ('presence', 'owe', 'segments'), ('part', 'equip', 'irrigation'), ('y', 'specify', 'variables'), ('area', 'measure', 'plot'), ('percent', 'apply', 'famers'), ('census', 'conduct', 'years'), ('it', 'harvest', 'hectare'), ('variable', 'specify', 'unit'), ('crops', 'mulberry', 'beer'), ('area', 'estimate', 'hectares'), ('cluster', 'follow', 'threshold'), ('karongi', 'sas', 'rulindo'), ('interview', 'use', 'questionnaire'), ('production', 'harvest', 'yield'), ('huye', 'sas', 'kayonza'), ('hectares', 'cover', 'crops'), ('effect', 'correspond', 'size'), ('rwamagana', 'sas', '0.7'), ('who', 'apply', 'fertilizers'), ('farmers', 'use', 'seeds'), ('huye', 'sas', '26.3'), ('percentage', 'sas', 'gakenke'), ('share', 'base', 'plants'), ('kicukiro', 'sas', 'nisr'), ('it', 'calculate', 'crop'), ('56.6', 'use', 'agriculture'), ('y', 'follow', '1'), ('cassava', 'have', 'ha'), ('ruhango', 'sas', 'nisr'), ('process', 'follow', 'segment'), ('consideration', 'capture', 'cultivation'), ('tools', 'cultivate', 'crops'), ('use', 'see', 'tables'), ('which', 'have', 'cassava'), ('data', 'use', 'stata'), ('which', 'refer', 'areas'), ('that', 'give', 'season'), ('karongi', 'sas', '1,513'), ('use', 'improve', 'seeds'), ('that', 'use', 'design'), ('collection', 'illustrate', 'figure1'), ('data', 'monitor', 'coffee'), ('non', 'protect', 'wetlands'), ('which', 'occupy', 'area'), ('survey', 'see', 'table'), ('techniques', 'see', 'tables'), ('production', 'harvest', 'district'), ('definition', 'include', 'rivers'), ('area', 'weight', 'district'), ('extent', 'estimate', 'data'), ('who', 'apply', 'practices'), ('dealers', 'crop', 'crops'), ('it', 'decrease', 'sample'), ('which', 'cover', 'rwanda'), ('which', 'screen', 'activity'), ('it', 'cluster', 'design'), ('kamonyi', 'sas', 'gicumbi'), ('area', 'equal', 'ha'), ('huye', 'sas', 'gakenke'), ('category', 'grow', 'wood'), ('crop', 'cover', 'plot'), ('staff', 'maintain', 'quality'), ('survey', 'sample', 'sas'), ('denominator', 'equal', 'weights'), ('nyabihu', 'sas', 'nisr'), ('that', 'select', 'sample'), ('channels', 'sas', 'nisr'), ('which', 'measure', 'estimate'), ('area', 'pasture', 'season'), ('probability', 'follow', 'selection'), ('area', 'cultivate', 'maize'), ('collection', 'harvest', 'seasons'), ('survey', 'nyamasheke', 'rulindo'), ('proportion', 'harvest', 'area'), ('clustering', 'increase', 'segments'), ('kamonyi', 'sas', 'ssf'), ('dealers', 'sas', 'beer'), ('indicators', 'maize', 'beer'), ('karongi', 'sas', 'nisr'), ('karongi', 'sas', '74.7'), ('sample', 'draw', 'it'), ('which', 'express', 'area'), ('trade', 'sas', 'losses'), ('who', 'grow', 'season'), ('huye', 'sas', '51.84'), ('percentage', 'practice', '1,067.2'), ('area', 'exclude', 'crops1'), ('who', 'apply', 'year'), ('who', 'sas', 'nisr'), ('phase', 'cultivate', 'plots'), ('that', 'indicate', 'land'), ('survey', 'relate', 'statistics'), ('huye', 'sas', 'm.d'), ('that', 'bring', 'land'), ('that', 'have', 'crop'), ('crops', 'sas', 'beer'), ('barter', 'sas', 'crops'), ('share', 'plant', 'plot'), ('report', 'relate', 'year'), ('area', 'equal', 'area'), ('it', 'screen', 'phases'), ('farmer', 'harvest', 'trees'), ('area', 'compare', '2022'), ('land', 'indicate', 'agriculture'), ('data', 'table', 'annexes'), ('summary', 'kgha', 'fruits'), ('survey', 'sqm', 'statistics'), ('musanze', 'sas', 'nisr'), ('di', 'sas', 'nisr'), ('land', 'graze', 'land'), ('c', 'use', 'seeds'), ('area', 'consider', 'density'), ('rwamagana', 'sas', 'nisr'), ('this', 'protect', 'erosion'), ('it', 'prove', 'sample'), ('gasabo', 'nyamasheke', '47.0'), ('varieties', 'grow', 'others'), ('some', 'relate', 'activities'), ('enumerators', 'connect', 'tablet'), ('which', 'take', 'frame'), ('land', 'include', 'category'), ('concepts', 'exclude', 'bodies'), ('points', 'relate', 'use'), ('which', 'use', 'worldview'), ('dealers', 'nyamasheke', '100.00'), ('crops', 'replant', 'cocoa'), ('percentage', 'sas', 'nisr'), ('57.5', 'use', 'agriculture'), ('di', 'sas', 'gro'), ('hectares', 'use', 'pasture'), ('phase', 'engage', 'lsf'), ('which', 'replant', 'harvest'), ('it', 'target', 'seasons'), ('percent', 'apply', 'pesticides'), ('five', 'consider', 'frame'), ('it', 'cover', 'segments'), ('quantity', 'quantify', 'kilograms'), ('between16', 'sas', 'crops'), ('farmer', 'cultivate', 'area'), ('total', 'constitute', 'sample'), ('ruhango', 'sas', 'gakenke'), ('section', 'harvest', 'use'), ('it', 'include', 'inputs'), ('segments', 'distribute', 'criterion'), ('share', 'apply', 'area'), ('production', '2023cultivate', 'type'), ('seeds', 'use', 'which'), ('estimate', 'consider', '20'), ('land', 'fallow', 'years'), ('value', 'show', 'prices'), ('area', 'include', 'crops'), ('huye', 'sas', 'nisr'), ('crop', 'occupy', 'area'), ('classes', 'exclude', 'agriculture'), ('which', 'divide', 'estimate'), ('inputs', 'include', 'seeds'), ('karongi', 'sas', '17.49'), ('karongi', 'sas', 'kayonza'), ('y', 'h', '2'), ('which', 'relate', 'interval'), ('musanze', 'sas', '14,637'), ('area', 'occupy', 'crops'), ('error', 'measure', 'variance'), ('potato', 'grow', 'zone'), ('pesticides', 'use', 'which'), ('it', 'estimate', 'cultivation'), ('barter', 'sas', 'beer'), ('karongi', 'sas', 'gicumbi'), ('segment', 'select', 'which'), ('data', 'holding', 'country'), ('area', 'cultivate', 'area'), ('yield', 'harvest', 'crop'), ('example', 'calculate', 'crop'), ('variable', 'refer', 'plots'), ('cv', 'indicate', '15'), ('dealers', 'kayonza', 'nyagatare'), ('enumerators', 'sample', 'segment'), ('nyabihu', 'sas', 'farmers'), ('karongi', 'nyamasheke', '18.85'), ('production', 'compare', '2022'), ('area', 'cover', 'crops'), ('government', 'invest', 'addition'), ('i', 'accord', 'total'), ('ruhango', 'nyamasheke', 'musanze'), ('demand', 'increase', 'data'), ('sum', 'exceed', 'percent'), ('estimates', 'give', 'district'), ('which', 'cover', 'frame'), ('percent', 'compare', 'c.'), ('inputs', 'highlight', 'inputs'), ('results', 'evidencebase', 'sector'), ('value', 'be', 'range'), ('crops', 'sas', 'gicumbi'), ('stratum', 'consider', 'agriculture'), ('points', 'follow', 'points'), ('team', 'ensure', 'hectares'), ('karongi', 'sas', '100'), ('software', 'sample', 'data'), ('gasabo', 'sas', 'nisr'), ('di', 'sas', 'npk'), ('who', 'write', 'alexis'), ('level', 'provide', 'information'), ('farmer', 'harvest', 'purposes'), ('yield', 'estimate', 'hectare'), ('kicukiro', 'sas', '6,277'), ('musanze', 'sas', 'ngoma'), ('each', 'cover', 'country'), ('4', 'sample', 'figures'), ('plots', 'use', 'size'), ('yield', 'compare', 'farmers'), ('use', 'sas', 'nisr'), ('step', 'consider', 'frame'), ('sas', 'combine', 'frame'), ('percent', 'apply', 'farmers'), ('rusizi', 'sas', '1,411'), ('clusters', 'state', 'reasons'), ('combination', 'relate', 'statistics'), ('huye', 'sas', '1,411'), ('karongi', 'sas', '0.7'), ('collection', 'grow', 'segments'), ('percent', 'see', 'tables'), ('that', 'describe', 'use'), ('that', 'cluster', 'design'), ('errors', 'sample', 'samples'), ('karongi', 'gakenke', 'kayonza'), ('statistics', 'evidencebase', 'making'), ('it', 'determine', 'period'), ('presence', 'owe', 'segments'), ('part', 'equip', 'irrigation'), ('y', 'specify', 'variables'), ('area', 'measure', 'plot'), ('percent', 'apply', 'famers'), ('census', 'conduct', 'years'), ('it', 'harvest', 'hectare'), ('variable', 'specify', 'unit'), ('crops', 'mulberry', 'beer'), ('area', 'estimate', 'hectares'), ('cluster', 'follow', 'threshold'), ('karongi', 'sas', 'rulindo'), ('interview', 'use', 'questionnaire'), ('production', 'harvest', 'yield'), ('huye', 'sas', 'kayonza'), ('hectares', 'cover', 'crops'), ('effect', 'correspond', 'size'), ('rwamagana', 'sas', '0.7'), ('who', 'apply', 'fertilizers'), ('farmers', 'use', 'seeds'), ('huye', 'sas', '26.3'), ('percentage', 'sas', 'gakenke'), ('share', 'base', 'plants'), ('kicukiro', 'sas', 'nisr'), ('it', 'calculate', 'crop'), ('56.6', 'use', 'agriculture'), ('y', 'follow', '1'), ('cassava', 'have', 'ha'), ('ruhango', 'sas', 'nisr'), ('process', 'follow', 'segment'), ('consideration', 'capture', 'cultivation'), ('tools', 'cultivate', 'crops'), ('use', 'see', 'tables'), ('which', 'have', 'cassava'), ('data', 'use', 'stata'), ('which', 'refer', 'areas'), ('that', 'give', 'season'), ('karongi', 'sas', '1,513'), ('use', 'improve', 'seeds'), ('that', 'use', 'design'), ('collection', 'illustrate', 'figure1'), ('data', 'monitor', 'coffee'), ('non', 'protect', 'wetlands'), ('which', 'occupy', 'area'), ('survey', 'see', 'table'), ('techniques', 'see', 'tables'), ('production', 'harvest', 'district'), ('definition', 'include', 'rivers'), ('area', 'weight', 'district'), ('extent', 'estimate', 'data'), ('who', 'apply', 'practices'), ('dealers', 'crop', 'crops'), ('it', 'decrease', 'sample'), ('which', 'cover', 'rwanda'), ('which', 'screen', 'activity'), ('it', 'cluster', 'design'), ('kamonyi', 'sas', 'gicumbi'), ('area', 'equal', 'ha'), ('huye', 'sas', 'gakenke')]\n",
      "\n",
      "Flagged entities saved to flagged_entities.json\n",
      "\n",
      "Flagged relationships saved to flagged_relationships.json\n"
     ]
    }
   ],
   "source": [
    "# Extract text, preprocess and extract entities and relationships from new data file\n",
    "new_file_path = 'files/Final_SAS 2023_Annual Report.pdf'\n",
    "flagged_entities, flagged_relationships = process_new_pdf(new_file_path)\n",
    "\n",
    "save_flagged_data(flagged_entities, flagged_relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Flagged Data, and Process the validated ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user then locates and opened the saved json files of the flagged entities and relationships, for review and validation. The user can remove all invalid and unwanted entities and relationships from the respective files while keeping the valid ones. When done, the user saves the files. These newly saved files now contained the validated entities and relationships respectively which the user can now use to update the existing knowledge graph and schema.\n",
    "\n",
    "Next, we’ll create a function for the user to process the validated data from the saved files to update the knowledge graph and existing schema. New entities and relationships will be added to the knowledge graph while updating the schema. Already existing entities are not added again to avoid duplicates, this is ensured in both the knowledge graph and schema. Similarly, already existing relationships between the same pair of entities are skipped as well to avoid duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_validated_data(graph, schema, entities_file=\"flagged_entities.json\", relationships_file=\"flagged_relationships.json\"):\n",
    "    # Load validated entities from file\n",
    "    with open(entities_file, \"r\") as ef:\n",
    "        validated_entities = json.load(ef)\n",
    "\n",
    "    # Add validated entities to the graph and schema\n",
    "    for entity, entity_type in validated_entities:\n",
    "        if not graph.has_node(entity):\n",
    "            graph.add_node(entity, label=entity_type)\n",
    "            print(f\"\\n{entity} added to graph\")\n",
    "            \n",
    "        if entity_type not in schema[\"entities\"]:\n",
    "            schema[\"entities\"].append(entity_type)\n",
    "            print(f\"\\n{entity_type} added to schema\")\n",
    "\n",
    "    # Load validated relationships from file\n",
    "    with open(relationships_file, \"r\") as rf:\n",
    "        validated_relationships = json.load(rf)\n",
    "\n",
    "    # Add validated relationships to the graph and schema\n",
    "    for subject, predicate, obj in validated_relationships:\n",
    "        # Ensure subject and object nodes exist in the graph\n",
    "        if not graph.has_node(subject):\n",
    "            graph.add_node(subject, label=\"Unknown\")\n",
    "        if not graph.has_node(obj):\n",
    "            graph.add_node(obj, label=\"Unknown\")\n",
    "        \n",
    "        # Retrieve node types\n",
    "        subject_type = graph.nodes[subject].get(\"label\", \"Unknown\")\n",
    "        obj_type = graph.nodes[obj].get(\"label\", \"Unknown\")\n",
    "\n",
    "        # Add edge and update schema\n",
    "        if not graph.has_edge(subject, obj):\n",
    "            graph.add_edge(subject, obj, label=predicate)\n",
    "            print(f\"\\n{subject}->{predicate}->{obj} relationship added to graph\")\n",
    "        if (subject_type, obj_type) not in schema[\"relationships\"]:\n",
    "            schema[\"relationships\"][(subject_type, obj_type)] = [predicate]\n",
    "            print(f\"\\n{subject_type}->{obj_type} relationship added to schema\")\n",
    "        elif predicate not in schema[\"relationships\"][(subject_type, obj_type)]:\n",
    "            schema[\"relationships\"][(subject_type, obj_type)].append(predicate)\n",
    "            print(f\"\\n{predicate} relationship added to schema\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def review_and_confirm(flagged_entities, flagged_relationships, graph, schema):\n",
    "#     # Process flagged entities\n",
    "#     for entity, entity_type in flagged_entities:\n",
    "#         user_input = input(f\"Confirm entity '{entity}' as type '{entity_type}'? (y/n): \")\n",
    "#         if user_input.lower() == \"y\":\n",
    "#             # Add entity to graph and schema, ensure it has a label\n",
    "#             graph.add_node(entity, label=entity_type)\n",
    "#             print(f\"{entity} added to graph\")\n",
    "#             if entity_type not in schema[\"entities\"]:\n",
    "#                 schema[\"entities\"].append(entity_type)\n",
    "#                 print(f\"{entity_type} added to schema\")\n",
    "\n",
    "\n",
    "#     # Process flagged relationships\n",
    "#     for subject, predicate, obj in flagged_relationships:\n",
    "#         # Ensure subject and object nodes have labels\n",
    "#         if not graph.has_node(subject):\n",
    "#             graph.add_node(subject, label=\"Unknown\")\n",
    "#         if not graph.has_node(obj):\n",
    "#             graph.add_node(obj, label=\"Unknown\")\n",
    "        \n",
    "#         # Retrieve labels, setting a default if missing\n",
    "#         subject_type = graph.nodes[subject].get(\"label\", \"Unknown\")\n",
    "#         obj_type = graph.nodes[obj].get(\"label\", \"Unknown\")\n",
    "\n",
    "#         # Prompt user for confirmation of relationship\n",
    "#         user_input = input(f\"Confirm relationship '{subject} - {predicate} - {obj}'? (y/n): \")\n",
    "#         if user_input.lower() == \"y\":\n",
    "#             # Add relationship to graph and update schema if necessary\n",
    "#             graph.add_edge(subject, obj, label=predicate)\n",
    "#             print(f\"relationship added to graph\")\n",
    "#             if (subject_type, obj_type) not in schema[\"relationships\"]:\n",
    "#                 schema[\"relationships\"][(subject_type, obj_type)] = [predicate]\n",
    "#                 print(f\"relationship added to schema\")\n",
    "\n",
    "#             elif predicate not in schema[\"relationships\"][(subject_type, obj_type)]:\n",
    "#                 schema[\"relationships\"][(subject_type, obj_type)].append(predicate)\n",
    "#                 print(f\"relationship added to schema\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to schema\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n",
      "\n",
      "relationship added to graph\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Reviewing flagged items\n",
    "# review_and_confirm(flagged_entities, flagged_relationships, knowledge_graph, schema)\n",
    "process_validated_data(knowledge_graph, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved to updated_agricultural_knowledge_graph.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "visualize_knowledge_graph_pyvis(knowledge_graph, output_path=\"updated_agricultural_knowledge_graph.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set up OpenAI API key\n",
    "my_openai_key = \"sk-OJ2_gW9HAKApES_5DbyRODLahM36bT13evmH3wxERkT3BlbkFJ5fwb2Eq-euILAFeg8IeJp5lw3MSHOxRFyB7Agjn28A\"\n",
    "\n",
    "client = OpenAI(api_key=\"sk-OJ2_gW9HAKApES_5DbyRODLahM36bT13evmH3wxERkT3BlbkFJ5fwb2Eq-euILAFeg8IeJp5lw3MSHOxRFyB7Agjn28A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract knowledge graph data based on keywords\n",
    "def query_knowledge_graph(graph, keywords):\n",
    "    results = []\n",
    "    for node in graph.nodes:\n",
    "        if any(keyword in node.lower() for keyword in keywords):\n",
    "            label = graph.nodes[node].get(\"label\", \"Unknown\")\n",
    "            results.append((node, label))\n",
    "    for edge in graph.edges(data=True):\n",
    "        subject, obj, data = edge\n",
    "        if any(keyword in subject.lower() for keyword in keywords) or any(keyword in obj.lower() for keyword in keywords):\n",
    "            relation = data.get(\"relation\", \"Unknown\")\n",
    "            results.append((subject, relation, obj))\n",
    "    return results\n",
    "\n",
    "# Function to query the LLM with knowledge graph context\n",
    "def query_llm_with_kg(question, graph):\n",
    "    keywords = question.lower().split()\n",
    "    kg_data = query_knowledge_graph(graph, keywords)\n",
    "    \n",
    "    # Construct context from knowledge graph findings\n",
    "    context = \"Relevant Knowledge Graph Data:\\n\"\n",
    "    for item in kg_data:\n",
    "        if len(item) == 2:\n",
    "            context += f\"- Entity: {item[0]}, Type: {item[1]}\\n\"\n",
    "        elif len(item) == 3:\n",
    "            context += f\"- Relationship: {item[0]} - {item[1]} -> {item[2]}\\n\"\n",
    "    \n",
    "    # Combine context with question\n",
    "    prompt = f\"{context}\\n\\nQuestion: {question}\"\n",
    "    \n",
    "    # Query LLM with combined prompt\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in agricultural knowledge.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    \n",
    "    answer = chat_completion.choices[0].message.content.strip()\n",
    "    return answer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Rwanda, the crops that typically grow in season A include:\n",
      "\n",
      "1. **Maize** - A staple crop widely cultivated in various regions.\n",
      "2. **Beans** - Commonly grown alongside maize, they are a significant source of protein.\n",
      "3. **Cassava** - A drought-resistant crop that is also a staple food.\n",
      "4. **Potatoes** - Particularly in the highland areas, potatoes are a popular crop.\n",
      "5. **Sweet potatoes** - Another important root crop that is cultivated in many areas.\n",
      "6. **Rice** - Grown in marshlands and areas with sufficient water supply.\n",
      "7. **Vegetables** - Various vegetables such as carrots, onions, and cabbages are also cultivated during this season.\n",
      "\n",
      "These\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question = \"What crops grow in season A in Rwanda?\"\n",
    "print(query_llm_with_kg(question, knowledge_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farmers practice irrigation for several reasons:\n",
      "\n",
      "1. **Water Supply**: Irrigation provides a reliable water supply to crops, especially in areas where rainfall is insufficient or irregular. This ensures that crops receive the necessary moisture for growth.\n",
      "\n",
      "2. **Crop Yield Improvement**: By maintaining optimal soil moisture levels, irrigation can significantly enhance crop yields. This is particularly important during dry spells or drought conditions.\n",
      "\n",
      "3. **Soil Fertility**: Irrigation helps in the distribution of nutrients in the soil, promoting better plant growth and health. It can also help in leaching out harmful salts from the soil.\n",
      "\n",
      "4. **Drought Mitigation**: In regions prone to drought, irrigation acts as a safeguard against crop failure, allowing farmers to sustain their\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question = \"why do farmers practice irrigation\"\n",
    "print(query_llm_with_kg(question, knowledge_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition behind this approach is to use the knowledge graph to enhance the LLM's response. Instead of relying solely on the LLM's pre-trained knowledge, the knowledge graph provides domain-specific, structured data (e.g., facts, relationships, entities) relevant to the user's query. This context is added to the prompt, guiding the LLM to generate an answer informed by the graph's information. By doing so, the LLM's output is more accurate, grounded in domain-specific knowledge, and aligned with the question's context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
